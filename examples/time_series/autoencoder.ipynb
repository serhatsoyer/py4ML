{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b323ddd0",
   "metadata": {},
   "source": [
    "### Feature Extraction with an AutoEncoder\n",
    "\n",
    "Refer to [/examples/time_series/generate_data.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/time_series/generate_data.ipynb) for the artificial time-series dataset (used in this example) generation  \n",
    "\n",
    "$32\\times 3$ matrix reduced to $8$ element vector with an autoencoder. Then, the encoder part has been merged with a simple MLP to classify *vers* of the input. Test accuracy is around $0.77$. Although the method has worked properly, [the straightforward method]([/examples/datasets_misc.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/datasets_misc.ipynb)) outperforms this feature extractor method with around $0.97$ test accuracy  \n",
    "\n",
    "Previous example: [/examples/autoencoders/lstm.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/autoencoders/lstm.ipynb)  \n",
    "Next example: [/examples/nlp/bidirectional.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/nlp/bidirectional.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92356f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../') # To be able to reach 'datasets' folder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import Input, BatchNormalization, GRU, Bidirectional, Dropout, RepeatVector, Dense, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8242cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train                  : (49152, 32, 3)\n",
      "y_train                  : (49152,)\n",
      "x_test                   : (12288, 32, 3)\n",
      "y_test                   : (12288,)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path.cwd().parent.parent / 'datasets' / 'time_series'\n",
    "\n",
    "input = np.load(dataset_path / 'input.npy')\n",
    "output = np.load(dataset_path / 'output.npy')\n",
    "\n",
    "# Try to classify vers for within=1, inter=0\n",
    "x_train, x_test, y_train, y_test = train_test_split(\\\n",
    "    np.concatenate((input[0], input[1])), \\\n",
    "    np.concatenate((np.zeros_like(output[1][0][0]), np.ones_like(output[1][0][1]))), \\\n",
    "    test_size=0.20, shuffle=True)\n",
    "\n",
    "del dataset_path, input, output\n",
    "def print_data(msg, data): print(f'{msg:25}: {data.shape}')\n",
    "print_data('x_train', x_train)\n",
    "print_data('y_train', y_train)\n",
    "print_data('x_test', x_test)\n",
    "print_data('y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f2df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:26:18.755744: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-04 15:26:18.755985: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 32, 3)            12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32, 64)            13248     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " encoder (GRU)               (None, 8)                 1776      \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 32, 8)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32, 128)          28416     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 128)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 32, 1)            129       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,581\n",
      "Trainable params: 43,575\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Input(x_train.shape[1:]))\n",
    "autoencoder.add(BatchNormalization())\n",
    "autoencoder.add(GRU(64, return_sequences=True))\n",
    "autoencoder.add(Dropout(1 / 32))\n",
    "autoencoder.add(GRU(8, activity_regularizer=l1(1e-4), name='encoder'))\n",
    "autoencoder.add(RepeatVector(32))\n",
    "autoencoder.add(Bidirectional(GRU(64, return_sequences=True)))\n",
    "autoencoder.add(Dropout(1 / 64))\n",
    "autoencoder.add(TimeDistributed(Dense(1)))\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=[RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2151f0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:26:19.409420: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-04 15:26:21.193704: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.540714: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.639820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.725305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.736493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.912956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:21.942222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:22.147198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:22.267115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/384 [============================>.] - ETA: 0s - loss: 28.0412 - rmse: 5.2954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:26:40.904618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:41.014964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:41.079927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:41.149656: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:26:41.158329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 24s 54ms/step - loss: 28.0381 - rmse: 5.2951 - val_loss: 25.4842 - val_rmse: 5.0482\n",
      "Epoch 2/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 24.6337 - rmse: 4.9632 - val_loss: 23.6950 - val_rmse: 4.8677\n",
      "Epoch 3/256\n",
      "384/384 [==============================] - 21s 54ms/step - loss: 23.8337 - rmse: 4.8819 - val_loss: 23.5507 - val_rmse: 4.8529\n",
      "Epoch 4/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 24.3988 - rmse: 4.9395 - val_loss: 23.2852 - val_rmse: 4.8254\n",
      "Epoch 5/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 23.4276 - rmse: 4.8402 - val_loss: 23.0166 - val_rmse: 4.7975\n",
      "Epoch 6/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 23.0471 - rmse: 4.8007 - val_loss: 22.4241 - val_rmse: 4.7354\n",
      "Epoch 7/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 22.6395 - rmse: 4.7581 - val_loss: 22.3622 - val_rmse: 4.7288\n",
      "Epoch 8/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 22.4929 - rmse: 4.7426 - val_loss: 22.1050 - val_rmse: 4.7016\n",
      "Epoch 9/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 22.3855 - rmse: 4.7313 - val_loss: 22.0198 - val_rmse: 4.6925\n",
      "Epoch 10/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 22.7229 - rmse: 4.7668 - val_loss: 22.4795 - val_rmse: 4.7412\n",
      "Epoch 11/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 22.9654 - rmse: 4.7922 - val_loss: 22.5528 - val_rmse: 4.7489\n",
      "Epoch 12/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 22.7369 - rmse: 4.7683 - val_loss: 22.4066 - val_rmse: 4.7335\n",
      "Epoch 13/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 22.3176 - rmse: 4.7241 - val_loss: 21.8902 - val_rmse: 4.6787\n",
      "Epoch 14/256\n",
      "384/384 [==============================] - 21s 54ms/step - loss: 22.0862 - rmse: 4.6996 - val_loss: 21.6501 - val_rmse: 4.6529\n",
      "Epoch 15/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.9269 - rmse: 4.6826 - val_loss: 21.4539 - val_rmse: 4.6318\n",
      "Epoch 16/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.8440 - rmse: 4.6737 - val_loss: 21.4459 - val_rmse: 4.6309\n",
      "Epoch 17/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.7791 - rmse: 4.6668 - val_loss: 21.4088 - val_rmse: 4.6269\n",
      "Epoch 18/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.7332 - rmse: 4.6618 - val_loss: 21.4681 - val_rmse: 4.6333\n",
      "Epoch 19/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.7387 - rmse: 4.6624 - val_loss: 21.4793 - val_rmse: 4.6345\n",
      "Epoch 20/256\n",
      "384/384 [==============================] - 21s 54ms/step - loss: 21.7089 - rmse: 4.6592 - val_loss: 21.5180 - val_rmse: 4.6387\n",
      "Epoch 21/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.5891 - rmse: 4.6464 - val_loss: 21.3120 - val_rmse: 4.6164\n",
      "Epoch 22/256\n",
      "384/384 [==============================] - 21s 53ms/step - loss: 21.6207 - rmse: 4.6498 - val_loss: 21.2867 - val_rmse: 4.6137\n",
      "Epoch 23/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.7600 - rmse: 4.6647 - val_loss: 21.4784 - val_rmse: 4.6344\n",
      "Epoch 24/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.6670 - rmse: 4.6547 - val_loss: 21.4522 - val_rmse: 4.6316\n",
      "Epoch 25/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.5825 - rmse: 4.6457 - val_loss: 21.2313 - val_rmse: 4.6077\n",
      "Epoch 26/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.5069 - rmse: 4.6375 - val_loss: 21.1375 - val_rmse: 4.5975\n",
      "Epoch 27/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.4321 - rmse: 4.6294 - val_loss: 21.1202 - val_rmse: 4.5956\n",
      "Epoch 28/256\n",
      "384/384 [==============================] - 22s 56ms/step - loss: 21.4113 - rmse: 4.6272 - val_loss: 21.0922 - val_rmse: 4.5926\n",
      "Epoch 29/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.4010 - rmse: 4.6261 - val_loss: 21.1131 - val_rmse: 4.5949\n",
      "Epoch 30/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.4030 - rmse: 4.6263 - val_loss: 21.0955 - val_rmse: 4.5929\n",
      "Epoch 31/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.3350 - rmse: 4.6189 - val_loss: 21.0393 - val_rmse: 4.5868\n",
      "Epoch 32/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.2666 - rmse: 4.6115 - val_loss: 20.9935 - val_rmse: 4.5818\n",
      "Epoch 33/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.2624 - rmse: 4.6111 - val_loss: 21.0183 - val_rmse: 4.5845\n",
      "Epoch 34/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.2604 - rmse: 4.6109 - val_loss: 20.9194 - val_rmse: 4.5737\n",
      "Epoch 35/256\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.2378 - rmse: 4.6084 - val_loss: 21.3898 - val_rmse: 4.6249\n",
      "Epoch 36/256\n",
      "384/384 [==============================] - 21s 54ms/step - loss: 21.3452 - rmse: 4.6200 - val_loss: 21.0429 - val_rmse: 4.5872\n",
      "Epoch 37/256\n",
      "384/384 [==============================] - 20s 52ms/step - loss: 21.3848 - rmse: 4.6243 - val_loss: 21.2464 - val_rmse: 4.6093\n",
      "Epoch 38/256\n",
      "384/384 [==============================] - ETA: 0s - loss: 21.3973 - rmse: 4.6257Restoring model weights from the end of the best epoch: 34.\n",
      "384/384 [==============================] - 20s 53ms/step - loss: 21.3973 - rmse: 4.6257 - val_loss: 21.3017 - val_rmse: 4.6153\n",
      "Epoch 38: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294903d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4, restore_best_weights=True)\n",
    "autoencoder.fit(x_train, x_train, epochs=256, batch_size=128, shuffle=True, validation_data=(x_test, x_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c16ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 3)]           0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 3)            12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32, 64)            13248     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " encoder (GRU)               (None, 8)                 1776      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,036\n",
      "Trainable params: 15,030\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs=autoencoder.inputs, outputs=autoencoder.get_layer('encoder').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6820a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 8)                 15036     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " out (Dense)                 (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,837\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 15,036\n",
      "_________________________________________________________________\n",
      "model.trainable = True\n",
      "model.layers[0].trainable = False\n",
      "model.layers[0].layers[0].trainable = False\n",
      "model.layers[0].layers[1].trainable = False\n",
      "model.layers[0].layers[-1].trainable = False\n",
      "model.layers[1].trainable = True\n",
      "model.layers[-1].trainable = True\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(encoder)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(1 / 32))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid', name='out'))\n",
    "model.layers[0].trainable = False\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "print(f'{model.trainable = }')\n",
    "print(f'{model.layers[0].trainable = }')\n",
    "print(f'{model.layers[0].layers[0].trainable = }')\n",
    "print(f'{model.layers[0].layers[1].trainable = }')\n",
    "print(f'{model.layers[0].layers[-1].trainable = }')\n",
    "print(f'{model.layers[1].trainable = }')\n",
    "print(f'{model.layers[-1].trainable = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd26f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_results(func, gt, pred, msg): print(f'{func.__name__} of {msg}:\\n{func(gt, pred)}')\n",
    "def analyse():\n",
    "    y_train_pred = np.float32(model.predict(x_train, batch_size=128, verbose=0) > .5)\n",
    "    y_test_pred = np.float32(model.predict(x_test, batch_size=128, verbose=0) > .5)\n",
    "    disp_results(classification_report, y_train, y_train_pred, 'training data')\n",
    "    disp_results(confusion_matrix, y_train, y_train_pred, 'training data')\n",
    "    print()\n",
    "    disp_results(classification_report, y_test, y_test_pred, 'test data')\n",
    "    disp_results(confusion_matrix, y_test, y_test_pred, 'test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e791cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:39:16.279562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:39:16.363283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:39:16.434439: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report of training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     24661\n",
      "         1.0       0.50      1.00      0.67     24491\n",
      "\n",
      "    accuracy                           0.50     49152\n",
      "   macro avg       0.25      0.50      0.33     49152\n",
      "weighted avg       0.25      0.50      0.33     49152\n",
      "\n",
      "confusion_matrix of training data:\n",
      "[[    0 24661]\n",
      " [    0 24491]]\n",
      "\n",
      "classification_report of test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      6059\n",
      "         1.0       0.51      1.00      0.67      6229\n",
      "\n",
      "    accuracy                           0.51     12288\n",
      "   macro avg       0.25      0.50      0.34     12288\n",
      "weighted avg       0.26      0.51      0.34     12288\n",
      "\n",
      "confusion_matrix of test data:\n",
      "[[   0 6059]\n",
      " [   0 6229]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/study/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Before Training:'); analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be07717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:39:22.274411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:39:22.429074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/384 [..............................] - ETA: 7:44 - loss: 0.6884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:39:22.502309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/384 [============================>.] - ETA: 0s - loss: 0.5567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:39:27.766710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:39:27.847782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-04 15:39:27.916360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 8s 16ms/step - loss: 0.5567 - val_loss: 0.5159\n",
      "Epoch 2/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.5140 - val_loss: 0.5008\n",
      "Epoch 3/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.5070 - val_loss: 0.4970\n",
      "Epoch 4/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.5035 - val_loss: 0.4994\n",
      "Epoch 5/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.5008 - val_loss: 0.4899\n",
      "Epoch 6/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4973 - val_loss: 0.4885\n",
      "Epoch 7/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4951 - val_loss: 0.4850\n",
      "Epoch 8/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4919 - val_loss: 0.4840\n",
      "Epoch 9/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4922 - val_loss: 0.4839\n",
      "Epoch 10/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4892 - val_loss: 0.4811\n",
      "Epoch 11/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4887 - val_loss: 0.4791\n",
      "Epoch 12/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4872 - val_loss: 0.4804\n",
      "Epoch 13/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4877 - val_loss: 0.4840\n",
      "Epoch 14/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4857 - val_loss: 0.4786\n",
      "Epoch 15/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4854 - val_loss: 0.4773\n",
      "Epoch 16/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4843 - val_loss: 0.4783\n",
      "Epoch 17/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4841 - val_loss: 0.4750\n",
      "Epoch 18/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4824 - val_loss: 0.4761\n",
      "Epoch 19/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4814 - val_loss: 0.4745\n",
      "Epoch 20/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4816 - val_loss: 0.4760\n",
      "Epoch 21/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4820 - val_loss: 0.4728\n",
      "Epoch 22/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4803 - val_loss: 0.4731\n",
      "Epoch 23/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4795 - val_loss: 0.4739\n",
      "Epoch 24/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4795 - val_loss: 0.4759\n",
      "Epoch 25/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4794 - val_loss: 0.4726\n",
      "Epoch 26/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4786 - val_loss: 0.4737\n",
      "Epoch 27/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4781 - val_loss: 0.4743\n",
      "Epoch 28/256\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4768 - val_loss: 0.4736\n",
      "Epoch 29/256\n",
      "383/384 [============================>.] - ETA: 0s - loss: 0.4764Restoring model weights from the end of the best epoch: 25.\n",
      "384/384 [==============================] - 6s 15ms/step - loss: 0.4762 - val_loss: 0.4729\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299334a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, epochs=256, batch_size=128, shuffle=True, validation_data=(x_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2335a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Training:\n",
      "classification_report of training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.78      0.78     24661\n",
      "         1.0       0.78      0.77      0.77     24491\n",
      "\n",
      "    accuracy                           0.77     49152\n",
      "   macro avg       0.77      0.77      0.77     49152\n",
      "weighted avg       0.77      0.77      0.77     49152\n",
      "\n",
      "confusion_matrix of training data:\n",
      "[[19285  5376]\n",
      " [ 5729 18762]]\n",
      "\n",
      "classification_report of test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.78      0.77      6059\n",
      "         1.0       0.78      0.77      0.78      6229\n",
      "\n",
      "    accuracy                           0.77     12288\n",
      "   macro avg       0.77      0.77      0.77     12288\n",
      "weighted avg       0.77      0.77      0.77     12288\n",
      "\n",
      "confusion_matrix of test data:\n",
      "[[4732 1327]\n",
      " [1445 4784]]\n"
     ]
    }
   ],
   "source": [
    "print('After Training:'); analyse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9112c149",
   "metadata": {},
   "source": [
    "Previous example: [/examples/autoencoders/lstm.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/autoencoders/lstm.ipynb)  \n",
    "Next example: [/examples/nlp/bidirectional.ipynb](https://github.com/serhatsoyer/py4ML/blob/main/examples/nlp/bidirectional.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "29d06b973d1ddb34db3279b24f9b5152402e688db937648b736e855ec4de60c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
